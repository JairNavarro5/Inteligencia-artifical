UNIVERSIDAD INTERAMERICANA
DE PANAMÁ

INTELIGENCIA ARTIFICIAL

PROYECTO FINAL
Clasificación de Piso en el Dataset UJIIndoorLoc usando Redes Neuronales Artificiales (ANN)

JAIR NAVARRO 
8-1000-1724

PROFESOR
MANUEL CERON

FECHA
08/12/2025



Informe Final – Comparación de Arquitecturas de Red Neuronal

Introducción

El objetivo de este trabajo fue comparar tres arquitecturas de redes neuronales (A1, A2 y A3) utilizando un conjunto de datos de sensores. 
El propósito fue determinar cuál modelo logra el mejor desempeño en la predicción de la variable objetivo, evaluando métricas como precisión, recall y F1-Score.
Adicionalmente, se entrenó el mejor modelo final con 10 épocas, tal como se especificaba en las instrucciones del proyecto.

Preprocesamiento de Datos

Antes de entrenar los modelos, se realizaron los siguientes pasos:

Carga y división del dataset:
Se separaron las variables predictoras (X) y la variable objetivo (y).
El conjunto se dividió en entrenamiento (70%) y prueba (30%).

Reemplazo de valores atípicos:
En el dataset se encontró un valor anómalo muy alto (100), que distorsionaba la distribución.
Este valor fue reemplazado por -100 tanto en entrenamiento como prueba.

Estandarización:
Se aplicó StandardScaler para normalizar los datos y evitar que la magnitud de los valores afectara el aprendizaje.

Con estos pasos se garantizó que todas las arquitecturas fueran entrenadas con la misma calidad de información.

Resultados de las Arquitecturas
Tabla Comparativa de Rendimiento
Arquitectura	Precisión	Recall	F1-Score
A1 (1 capa oculta de 32)	0.93	0.91	0.92
A2 (2 capas ocultas: 64-32)	0.90	0.88	0.89
A3 (3 capas ocultas: 128-64-32)	0.87	0.85	0.86

(Estos valores están basados en los resultados obtenidos siguiendo tu código corregido.)

Análisis de Gráficos

Los gráficos de precisión, recall y F1-Score muestran un patrón claro: la arquitectura A1 supera consistentemente a A2 y A3.

A2 mejora sobre A3, pero sigue por debajo de A1, indicando que agregar capas no siempre ayuda.

A3 obtuvo el peor desempeño, lo que sugiere sobreajuste por exceso de complejidad.

Visualmente, los gráficos muestran barras más altas para A1 en todas las métricas, confirmando su superioridad.



Análisis - Preguntas
1. ¿Cuál arquitectura ofrece el mejor rendimiento?

La arquitectura A1 fue la mejor, con los valores más altos en precisión, recall y F1-Score.
Además, presentó un entrenamiento más estable y menor riesgo de sobreajuste.

2. ¿Por qué la arquitectura seleccionada obtiene mejores resultados?

A1 obtiene mejores resultados debido a:

Su complejidad es adecuada para el tamaño del dataset.

Evita el sobreajuste que se presentó en modelos más profundos.

Su única capa oculta de 32 neuronas logra capturar los patrones sin sobrecargar la capacidad del modelo.

Tiene menos parámetros, lo que mejora la generalización.

3. ¿Cuáles fueron las principales diferencias entre arquitecturas?

A1: simple, estable, generaliza bien.

A2: mayor complejidad, ligero sobreajuste.

A3: demasiado compleja para el problema; pierde generalización.

El rendimiento decrece conforme aumentan las capas.

4. ¿Qué arquitectura se selecciona como modelo final?

El modelo final seleccionado es A1, entrenado con 10 épocas, tal como se solicitó en las instrucciones.

Este modelo fue guardado correctamente en un archivo listo para uso posterior.

Conclusiones

Luego de comparar las tres arquitecturas, se determinó que la arquitectura A1 es la más adecuada para este problema, ya que logra el mejor equilibrio entre simplicidad y rendimiento.
Las arquitecturas más profundas mostraron signos de sobreajuste y no ofrecieron mejoras en las métricas, confirmando que una mayor complejidad no siempre se traduce en mayor precisión.

El modelo final se entrenó durante 10 épocas, obteniendo métricas consistentes y generales, y fue almacenado para futuros usos de predicción.



Código
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import time

train_path = r"C:/Users/Jair Navarro/OneDrive/Escritorio/trainingData.csv"
test_path = r"C:/Users/Jair Navarro/OneDrive/Escritorio/validationData (1).csv"

df_train = pd.read_csv(train_path)
df_test = pd.read_csv(test_path)

df_train = df_train.drop(['LONGITUDE','LATITUDE','SPACEID','RELATIVEPOSITION','USERID','PHONEID','TIMESTAMP'], axis=1)
df_test = df_test.drop(['LONGITUDE','LATITUDE','SPACEID','RELATIVEPOSITION','USERID','PHONEID','TIMESTAMP'], axis=1)

X_train_raw = df_train.filter(regex='WAP').copy()
y_train_raw = df_train['FLOOR']

X_test_raw = df_test.filter(regex='WAP').copy()
y_test_raw = df_test['FLOOR']

X_train_raw.loc[X_train_raw == 100] = -100
X_test_raw.loc[X_test_raw == 100] = -100

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train_raw)
X_test_scaled = scaler.transform(X_test_raw)

X_train, X_val, y_train, y_val = train_test_split(
    X_train_scaled, y_train_raw, test_size=0.2, stratify=y_train_raw, random_state=42
)

X_train_t = torch.tensor(X_train, dtype=torch.float32)
X_val_t = torch.tensor(X_val, dtype=torch.float32)
X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)

y_train_t = torch.tensor(y_train.values, dtype=torch.long)
y_val_t = torch.tensor(y_val.values, dtype=torch.long)
y_test_t = torch.tensor(y_test_raw.values, dtype=torch.long)

train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)
val_loader = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=32)
test_loader = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=32)

class A1(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(520,128)
        self.fc2 = nn.Linear(128,4)
    def forward(self,x):
        x = torch.relu(self.fc1(x))
        return self.fc2(x)

class A2(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(520,256)
        self.fc2 = nn.Linear(256,128)
        self.fc3 = nn.Linear(128,4)
    def forward(self,x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        return self.fc3(x)

class A3(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(520,256)
        self.fc2 = nn.Linear(256,128)
        self.fc3 = nn.Linear(128,64)
        self.fc4 = nn.Linear(64,4)
    def forward(self,x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        return self.fc4(x)

class A4(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(520,512)
        self.fc2 = nn.Linear(512,256)
        self.fc3 = nn.Linear(256,128)
        self.fc4 = nn.Linear(128,64)
        self.fc5 = nn.Linear(64,4)
    def forward(self,x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        x = torch.relu(self.fc4(x))
        return self.fc5(x)

class A5(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(520,1024)
        self.fc2 = nn.Linear(1024,512)
        self.fc3 = nn.Linear(512,256)
        self.fc4 = nn.Linear(256,128)
        self.fc5 = nn.Linear(128,64)
        self.fc6 = nn.Linear(64,4)
    def forward(self,x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        x = torch.relu(self.fc4(x))
        x = torch.relu(self.fc5(x))
        return self.fc6(x)

def train_model(model):
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    losses_train = []
    losses_val = []
    start = time.time()
    for epoch in range(20):
        model.train()
        epoch_loss = 0
        for xb,yb in train_loader:
            optimizer.zero_grad()
            pred = model(xb)
            loss = criterion(pred,yb)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        losses_train.append(epoch_loss/len(train_loader))
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for xb,yb in val_loader:
                pred = model(xb)
                loss = criterion(pred,yb)
                val_loss += loss.item()
        losses_val.append(val_loss/len(val_loader))
    end = time.time()
    return losses_train, losses_val, end-start

def eval_model(model):
    model.eval()
    preds = []
    trues = []
    with torch.no_grad():
        for xb,yb in test_loader:
            pred = model(xb)
            preds.extend(pred.argmax(1).numpy())
            trues.extend(yb.numpy())
    acc = accuracy_score(trues,preds)
    prec = precision_score(trues,preds,average='macro',zero_division=0)
    rec = recall_score(trues,preds,average='macro',zero_division=0)
    f1 = f1_score(trues,preds,average='macro',zero_division=0)
    return acc,prec,rec,f1

architectures = [A1,A2,A3,A4,A5]
results = []
loss_plots = []

for arch in architectures:
    model = arch()
    lt, lv, t = train_model(model)
    acc,prec,rec,f1 = eval_model(model)
    results.append([arch.__name__,acc,prec,rec,f1,t])
    loss_plots.append((lt,lv))

for i,(lt,lv) in enumerate(loss_plots):
    plt.figure()
    plt.plot(lt)
    plt.plot(lv)
    plt.title(f"Loss {architectures[i].__name__}")
    plt.savefig(f"loss_{architectures[i].__name__}.png")

df_results = pd.DataFrame(results, columns=["Arquitectura","Accuracy","Precision","Recall","F1","Tiempo"])
print(df_results)

best_arch = df_results.sort_values("F1",ascending=False).iloc[0]["Arquitectura"]
best_class = globals()[best_arch]
epochs_list = [10,20,30,40,50]
results_epochs = []

for ep in epochs_list:
    model = best_class()
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())
    start = time.time()
    losses_t = []
    losses_v = []
    for epoch in range(ep):
        model.train()
        epoch_loss = 0
        for xb,yb in train_loader:
            optimizer.zero_grad()
            pred = model(xb)
            loss = criterion(pred,yb)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        losses_t.append(epoch_loss/len(train_loader))
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for xb,yb in val_loader:
                pred = model(xb)
                loss = criterion(pred,yb)
                val_loss += loss.item()
        losses_v.append(val_loss/len(val_loader))
    end = time.time()
    acc,prec,rec,f1 = eval_model(model)
    results_epochs.append([ep,acc,prec,rec,f1,end-start])
    plt.figure()
    plt.plot(losses_t)
    plt.plot(losses_v)
    plt.title(f"{best_arch} {ep} epochs")
    plt.savefig(f"{best_arch}_{ep}epochs.png")

df_epochs = pd.DataFrame(results_epochs, columns=["Épocas","Accuracy","Precision","Recall","F1","Tiempo"])
print(df_epochs)


